{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwJAAp0A27Ay"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nasa-gcn/circulars-nlp-paper/blob/main/topic-modeling/notebooks/unsupervised_astrophysical_topics.ipynb)\n",
        "\n",
        "\n",
        "#**Unsupervised Topic Modeling of NASA GCN Circulars with BERTopic**\n",
        "\n",
        "The [General Coordinates Network (GCN) Circulars](https://gcn.nasa.gov/circulars) serve as a real-time communication platform for the astrophysics community, enabling the rapid dissemination of discoveries such as gamma-ray bursts, gravitational-wave events, neutrino detections, and other transient phenomena. With three decades of accumulated data spanning more than forty thousands of Circulars, this archive serve as rich scientific resource. However, the unstructured and rapidly written nature of these reports makes systematic analysis and organization challenging.\n",
        "\n",
        "This project aims to leverage BERTopic, a state-of-the-art transformer-powered topic modeling framework, to automatically identify, cluster, and summarize the major themes within the GCN circular database. By combining:\n",
        "- **SentenceTransformers** for semantic embeddings  \n",
        "- **UMAP** for dimensionality reduction  \n",
        "- **HDBSCAN** for unsupervised clustering  \n",
        "- **LLMs (e.g., Mistral 7B)** for human-readable topic labels  \n",
        "\n",
        "This pipeline different research themes, and scientific trends in GCN circulars.\n",
        "\n",
        "## ⚙️ Setup Instructions\n",
        "\n",
        "- This notebook is designed for **Google Colab**.  \n",
        "- Before running, create a free [HuggingFace account](https://huggingface.co/) and generate an access token.  \n",
        "- Store the token in **Colab’s Secrets** as `HF_LOGIN_TOKEN` and enable notebook access (guide: [Using secrets in Colab](https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0)).  \n",
        "\n",
        "\n",
        "## ⚠️ Runtime Notes\n",
        "\n",
        "- For reproducible results, **run all cells sequentially and only once**.  \n",
        "- Re-running without restarting the runtime may lead to small variations due to the stochastic nature of **UMAP** and **HDBSCAN**.  \n",
        "- We recommend using **Colab’s L4 GPU runtime** (available with Colab Pro, ~$10/month), which was used in our outputs. Other GPU runtimes will also work but may yield slight deviations.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5edOPX82Nyc7"
      },
      "source": [
        "#Step 1: Download Data and Install necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKgxLYvxt90i",
        "outputId": "e8174177-8e52-47b1-a607-aa768eb7c9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-07 15:31:03--  https://raw.githubusercontent.com/nasa-gcn/circulars-nlp-paper/main/data/archive_2025.json.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27323287 (26M) [application/octet-stream]\n",
            "Saving to: ‘/content/archive_2025.json.tar.gz’\n",
            "\n",
            "/content/archive_20 100%[===================>]  26.06M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-10-07 15:31:04 (212 MB/s) - ‘/content/archive_2025.json.tar.gz’ saved [27323287/27323287]\n",
            "\n",
            "--2025-10-07 15:31:04--  https://raw.githubusercontent.com/nasa-gcn/circulars-nlp-paper/main/data/custom_stopwords.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12041 (12K) [text/plain]\n",
            "Saving to: ‘/content/custom_stopwords.txt’\n",
            "\n",
            "/content/custom_sto 100%[===================>]  11.76K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-10-07 15:31:04 (12.1 MB/s) - ‘/content/custom_stopwords.txt’ saved [12041/12041]\n",
            "\n",
            "Downloaded archive_2025.json.tar.gz and custom_stopwords.txt to /content\n"
          ]
        }
      ],
      "source": [
        "# Download the data and stopwords (uncomment to run in Colab)\n",
        "# If you already uploaded the files to /content, you can skip this cell.\n",
        "\n",
        "!wget https://raw.githubusercontent.com/nasa-gcn/circulars-nlp-paper/main/data/archive_2025.json.tar.gz -O /content/archive_2025.json.tar.gz\n",
        "!wget https://raw.githubusercontent.com/nasa-gcn/circulars-nlp-paper/main/data/custom_stopwords.txt -O /content/custom_stopwords.txt\n",
        "print(\"Downloaded archive_2025.json.tar.gz and custom_stopwords.txt to /content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSmeoMWxtCIs",
        "outputId": "05746715-1785-4d7f-e746-061b0ebd97fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install dependencies (run once)\n",
        "# NOTE: these installs might take a ~15 minutes in Colab for T4 GPU.\n",
        "\n",
        "%pip install bertopic==0.16.2 -qqq\n",
        "!CMAKE_ARGS=\"-DGGML_CUDA=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.3.9 -qqq\n",
        "!wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qXSkpOy36e7"
      },
      "source": [
        "#Step 2: Extract GCN Circulars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4LBIsnqvN26"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "(a) Extract circular JSONs from tar file.\n",
        "(b) Extract circular bodies from JSON list.\n",
        "'''\n",
        "import tarfile\n",
        "import json\n",
        "import os\n",
        "\n",
        "with tarfile.open('./archive_2025.json.tar.gz', 'r') as file:\n",
        "  file.extractall(path='./all_gcn_circulars')\n",
        "\n",
        "dir = os.listdir('./all_gcn_circulars/archive.json') #Store all file names as strings in dir\n",
        "\n",
        "#Add file path to beginning of file names in dir\n",
        "dir = ['./all_gcn_circulars/archive.json/' + filename for filename in sorted(dir)]\n",
        "\n",
        "print(f'Number of Circular JSONs: {len(dir)}\\n')\n",
        "print(f'First JSON path is: {dir[0]}')\n",
        "\n",
        "\n",
        "circulars = []\n",
        "circular_bodies = []\n",
        "time_stamps = []\n",
        "for file in dir:\n",
        "  with open(file, encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "    circulars.append(data)\n",
        "    circular_bodies.append(data[\"subject\"]+data[\"body\"])\n",
        "    time_stamps.append(data[\"createdOn\"])\n",
        "\n",
        "print(f'The first circular is:\\n {circulars[0]}\\n')\n",
        "print(f'The first circular body is:\\n {circular_bodies[0]}')\n",
        "\n",
        "'''\n",
        "Remove all undefined characters.\n",
        "'''\n",
        "\n",
        "clean_texts = []\n",
        "for text in circular_bodies:\n",
        "  clean_text = text.replace('�', '')\n",
        "  clean_texts.append(clean_text)\n",
        "\n",
        "circular_bodies = clean_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqKXDs1FqgBb"
      },
      "source": [
        "#Step 3: Create Custom Stopwords List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IJJcomqqPGP"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We will remove common English stopwords, punctuations, numbers, emails, and urls for preliminary statistical analysis and topic representations.\n",
        "We will also remove a hand-selected list of stopwords that do not add any value to our representations.\n",
        "As BERT uses a transformer based embedding model, it requires stopwords to build accurate embeddings.\n",
        "So removing stopwords before this step is unadvised.\n",
        "However, we can remove stopwords after embedding and clustering.\n",
        "We will use sklearn's WordVectorizer for this.\n",
        "'''\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "nltk.download('stopwords') # NLTK package for stopwords list\n",
        "\n",
        "new_stop_words = []\n",
        "new_stop_words = stopwords.words('english') #NLTK standard list of stopwords\n",
        "punctuation_list = list(string.punctuation) #Standard list of punctuations\n",
        "new_stop_words.extend(punctuation_list)\n",
        "\n",
        "# Get list of numbers and urls in circulars\n",
        "num_list = []\n",
        "url_list = []\n",
        "http_regex = re.compile(r\"http.*\")\n",
        "\n",
        "for text in circular_bodies:\n",
        "  word_list = text.split()\n",
        "\n",
        "  for word in word_list:\n",
        "    try:\n",
        "      float(word) # Check if word is numeric. Throws Value Error otherwise\n",
        "      num_list.append(word)\n",
        "    except ValueError:\n",
        "      pass\n",
        "\n",
        "    if re.match(http_regex, word): # Check if word begins with http\n",
        "      url_list.append(word)\n",
        "\n",
        "# Get list of emails\n",
        "email_list=[]\n",
        "for circular in circulars:\n",
        "  if \"email\" in circular:\n",
        "    email_list.append(circular[\"email\"])\n",
        "\n",
        "num_list = list(set(num_list)) # Remove duplicates\n",
        "new_stop_words.extend(num_list)\n",
        "\n",
        "url_list = list(set(url_list))\n",
        "new_stop_words.extend(url_list)\n",
        "\n",
        "email_list = list(set(email_list))\n",
        "new_stop_words.extend(email_list)\n",
        "\n",
        "with open('custom_stopwords.txt') as f:\n",
        "  for word in f:\n",
        "    new_stop_words.append(word.lower().strip())\n",
        "\n",
        "vectorizer_model = CountVectorizer(stop_words=new_stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nwZhk1A8OKt"
      },
      "source": [
        "#Step 4: Preliminary Statistics and Word cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUAt4gbh8HPa"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Get word count distribution over all circulars.\n",
        "'''\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sns.set_theme()\n",
        "\n",
        "counts=[]\n",
        "for text in circular_bodies:\n",
        "  counts.append(len(text.split()))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(counts, range=(0,1000), bins=100, color=sns.color_palette(\"Set2\", 1))\n",
        "plt.xlabel(\"Word Count\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Word Counts of Circular Bodies\")\n",
        "plt.xticks(np.arange(0, 1001, 100))\n",
        "plt.show()\n",
        "\n",
        "counts_over_1000 = [count>1000 for count in counts]\n",
        "print(f'Number of circulars with > 1000 words: {sum(counts_over_1000)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McK57eQtbsZa"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create word cloud over all GCN circulars.\n",
        "Includes bigrams and trigrams of words.\n",
        "'''\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "word_cloud = WordCloud(\n",
        "    collocations = True,\n",
        "    background_color = 'white',\n",
        "    max_words=100,\n",
        "    width=800,\n",
        "    height=600,\n",
        "    stopwords=new_stop_words).generate(' '.join(circular_bodies))\n",
        "\n",
        "plt.imshow(word_cloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "Print the list of words in the word cloud\n",
        "'''\n",
        "\n",
        "# word_frequencies = word_cloud.words_\n",
        "# words = list(word_frequencies.keys())\n",
        "# for word in words:\n",
        "#   print(word)\n",
        "\n",
        "#circular_bodies = circular_bodies[35000:39000]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phnVmCY1HoBn"
      },
      "source": [
        "#Step 5: Compute sentence-transformer embeddings and save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdyjnshP6nD_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Embed our circulars using the base all-MiniLM-L6-v2 model.\n",
        "'''\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Default model. Really fast, but only has context window of 256 tokens\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "minilm_l6_embeddings = model.encode(circular_bodies, show_progress_bar=True)\n",
        "np.save('minilm_l6_embeddings.npy', minilm_l6_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTpJcK3lk1BK"
      },
      "source": [
        "#Step 6: Perform Topic Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87DBYwBTdAXl"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Initialize Llama cpp model and AutoTokenizer\n",
        "'''\n",
        "from transformers import AutoTokenizer\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# Huggingface login required to use Mistral 7B Instruct\n",
        "# Make sure to save your own Huggingface login token in your Notebook's Secrets as 'HF_LOGIN_TOKEN'\n",
        "login_token = userdata.get('gcn-hf-1')\n",
        "login(token=login_token)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "llm = Llama(model_path=\"mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
        "            n_gpu_layers=-1,\n",
        "            n_ctx=32768)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "b__AJWXPSe63",
        "outputId": "46c0e68f-ae58-43b7-831d-e236a7ce58cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-10-07 07:04:41,204 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
            "2025-10-07 07:05:57,891 - BERTopic - Dimensionality - Completed ✓\n",
            "2025-10-07 07:05:57,893 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
            "2025-10-07 07:05:59,627 - BERTopic - Cluster - Completed ✓\n",
            "2025-10-07 07:05:59,641 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
            "2025-10-07 07:06:09,956 - BERTopic - Representation - Completed ✓\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89.90660309791565\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Document  Topic  \\\n",
              "0  Possible new SGR from US Naval ObservatoryThe ...      5   \n",
              "1  RXTE Observations of SGR 1814-13Don Smith on b...      0   \n",
              "2  GRB 970828: Palomar ObservationsFor the recent...      0   \n",
              "3  GRB 970228: Keck/LRIS Optical ObservationsShri...      0   \n",
              "4  IRAS 18119-1342 and the possible new SGRGeorge...      0   \n",
              "\n",
              "                             Name  \\\n",
              "0       5_konuswind_grb_burst_ipn   \n",
              "1  0_optical_grb_afterglow_images   \n",
              "2  0_optical_grb_afterglow_images   \n",
              "3  0_optical_grb_afterglow_images   \n",
              "4  0_optical_grb_afterglow_images   \n",
              "\n",
              "                                      Representation  \\\n",
              "0  [konuswind, grb, burst, ipn, chi2, triangulati...   \n",
              "1  [optical, grb, afterglow, images, photometry, ...   \n",
              "2  [optical, grb, afterglow, images, photometry, ...   \n",
              "3  [optical, grb, afterglow, images, photometry, ...   \n",
              "4  [optical, grb, afterglow, images, photometry, ...   \n",
              "\n",
              "                                 Representative_Docs  \\\n",
              "0  [IPN triangulation of GRB030726 (large error b...   \n",
              "1  [GRB 091024: optical observationsV. Rumyantsev...   \n",
              "2  [GRB 091024: optical observationsV. Rumyantsev...   \n",
              "3  [GRB 091024: optical observationsV. Rumyantsev...   \n",
              "4  [GRB 091024: optical observationsV. Rumyantsev...   \n",
              "\n",
              "                                         Top_n_words  Probability  \\\n",
              "0  konuswind - grb - burst - ipn - chi2 - triangu...     0.127837   \n",
              "1  optical - grb - afterglow - images - photometr...     1.000000   \n",
              "2  optical - grb - afterglow - images - photometr...     1.000000   \n",
              "3  optical - grb - afterglow - images - photometr...     0.776288   \n",
              "4  optical - grb - afterglow - images - photometr...     0.701472   \n",
              "\n",
              "   Representative_document  \n",
              "0                    False  \n",
              "1                    False  \n",
              "2                    False  \n",
              "3                    False  \n",
              "4                    False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fc3fe85-2d5b-4308-9d5f-971baed3c081\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>Representative_Docs</th>\n",
              "      <th>Top_n_words</th>\n",
              "      <th>Probability</th>\n",
              "      <th>Representative_document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Possible new SGR from US Naval ObservatoryThe ...</td>\n",
              "      <td>5</td>\n",
              "      <td>5_konuswind_grb_burst_ipn</td>\n",
              "      <td>[konuswind, grb, burst, ipn, chi2, triangulati...</td>\n",
              "      <td>[IPN triangulation of GRB030726 (large error b...</td>\n",
              "      <td>konuswind - grb - burst - ipn - chi2 - triangu...</td>\n",
              "      <td>0.127837</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RXTE Observations of SGR 1814-13Don Smith on b...</td>\n",
              "      <td>0</td>\n",
              "      <td>0_optical_grb_afterglow_images</td>\n",
              "      <td>[optical, grb, afterglow, images, photometry, ...</td>\n",
              "      <td>[GRB 091024: optical observationsV. Rumyantsev...</td>\n",
              "      <td>optical - grb - afterglow - images - photometr...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GRB 970828: Palomar ObservationsFor the recent...</td>\n",
              "      <td>0</td>\n",
              "      <td>0_optical_grb_afterglow_images</td>\n",
              "      <td>[optical, grb, afterglow, images, photometry, ...</td>\n",
              "      <td>[GRB 091024: optical observationsV. Rumyantsev...</td>\n",
              "      <td>optical - grb - afterglow - images - photometr...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GRB 970228: Keck/LRIS Optical ObservationsShri...</td>\n",
              "      <td>0</td>\n",
              "      <td>0_optical_grb_afterglow_images</td>\n",
              "      <td>[optical, grb, afterglow, images, photometry, ...</td>\n",
              "      <td>[GRB 091024: optical observationsV. Rumyantsev...</td>\n",
              "      <td>optical - grb - afterglow - images - photometr...</td>\n",
              "      <td>0.776288</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IRAS 18119-1342 and the possible new SGRGeorge...</td>\n",
              "      <td>0</td>\n",
              "      <td>0_optical_grb_afterglow_images</td>\n",
              "      <td>[optical, grb, afterglow, images, photometry, ...</td>\n",
              "      <td>[GRB 091024: optical observationsV. Rumyantsev...</td>\n",
              "      <td>optical - grb - afterglow - images - photometr...</td>\n",
              "      <td>0.701472</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fc3fe85-2d5b-4308-9d5f-971baed3c081')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3fc3fe85-2d5b-4308-9d5f-971baed3c081 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3fc3fe85-2d5b-4308-9d5f-971baed3c081');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a407a4a4-bea9-4ee2-8f6a-b7e1f9e7bf8f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a407a4a4-bea9-4ee2-8f6a-b7e1f9e7bf8f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a407a4a4-bea9-4ee2-8f6a-b7e1f9e7bf8f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "document_info",
              "summary": "{\n  \"name\": \"document_info\",\n  \"rows\": 40506,\n  \"fields\": [\n    {\n      \"column\": \"Document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40485,\n        \"samples\": [\n          \"GRB 190530A: Mondy and AbAO optical observationsS. Belkin (IKI),  E. Klunko (ISTP), R. Ya. Inasaridze (AbAO), A. \\nPozanenko (IKI), V.R. Ayvazian (AbAO), E. Mazaeva (IKI), A. Volnova \\n(IKI) report on behalf of IKI GRB FuN collaboration:\\n\\nWe continue observations the  optical afterglow (Lipunov et al., GCN \\n24680, 24693 and also e.g. Kann et al., GCN 24684; Melandri et al., GCN \\n24689; Heintz et al., GCN 24686; Lzzo et al., GCN  24687; Xin et al., \\nGCN   24688; Watson et al., GCN  24690; Xin et al., GCN 24697)  of the \\nFermi GRB 190530A (Fermi GBM Team, GCN  24676; Longo et al., GCN \\n24679) with   AZT-33IK telescope of Sayan observatory (Mondy) and AS-32 \\n(0.7m) telescope of Abastumani Observatory. The afterglow is clearly \\nvisible in stacked images. Preliminary photometry of the afterglow is \\nfollowing.\\n\\nDate        UT start t-T0   Filter Exp.   OT    Err. UL\\n                      (mid, days) (s)\\n\\n2019-06-01  15:35:00 2.23638  R    29*60 19.62  0.07  21.2\\n2019-06-01  17:38:57 2.31769  R    30*60 19.70  0.14  20.6\\n\\nThe photometry is based on the nearby USNO-B1.0 stars\\n\\nUSNO-B1.0_id R2\\n1255-0157926 13.35\\n1254-0159410 12.63\\n1255-0157793 13.56\\n\\nThe photometry might be influenced by nearby optical source presented in \\n    Pan-STARRS DR1 catalog (ID 150571205309266249) mentioned in (Lipunov \\net al., GCN 24680).\",\n          \"GRB 200216B: z-band limit from NOTA. de Ugarte Postigo (IAA-CSIC, DARK/NBI), J. Martikainen (NOT and \\nU. Helsinki), D. Perley (LJMU), K.E. Heintz (U. Iceland), D. Xu (NAOC),\\nA. Levan (Radboud U.) report on behalf of a larger collaboration:\\n\\nWe observed the field of GRB 200216B (Fermi GBM team GCN \\n27101; DAvanzo et al. GCN 27102) with the 2.5 m Nordic Optical \\nTelescope equipped with AlFOSC. Observations consisted of 5x200s \\nimaging in z-band, with mean epoch 17 Feb 2020 00:11:22 UT \\n(10.647 hr after the burst). We do not detect any source within the \\nrefined XRT error box (Goad et al. GCN 27106) down to a 3-sigma \\nlimit of z > 23.3 mag.\",\n          \"GRB 071003: VLT spectroscopyD. Fugazza (INAF-OABr), F. Fiore, V. D'Elia (INAF-OAR), P. D'Avanzo \\n(INAF-OABr), S. Piranomonte, L.A. Antonelli (INAF-OAR), G. Chincarini \\n(Univ. Bicocca), S. Covino, G. Tagliaferri (INAF-OABr), M. Della Valle \\n(INAF-OAA), A. Fernandez Soto (Univ. Valencia) report on behalf of the \\nMISTICI collaboration:\\n\\nWe observed the optical afterglow of GRB 071003 (Schady et al., GCN \\n6837; Li et al. GCN 6838; Cenko et al. GCN 6839) with the ESO-Very Large \\nTelescope equipped with the FORS2 camera in spectroscopic mode. We took \\na 1800s spectrum with the grism 600B (with a resolution of R = 780) on \\nOct 04.055 UT (~ 0.735 days after the burst), under good seeing \\nconditions (1.0\\\").\\n\\nThe detection of a MgII system at z=1.100 (Perley et al. GCN 6850), \\ncannot be confirmed by our data, because the 2803 AA component of the \\nMgII doublet is contamined by the NaI 5891 and 5897 AA doublet of the \\nnearby bright star.\\n\\nWe also find significant lines at 5417 and 5430 AA, which we interpret \\nas the MgII absorption doublet at 2797 and 2803 AA at z=0.937. FeII 2382 \\nis also detected at the same redshift.\\n\\nIn addition, we find two more significant absorption lines (5417 and \\n5446 AA), that can be identified as Ca H and K at z=0.372. \\nAlternatively, the 5446 AA line can be interpreted as the  2803 AA \\ncomponent of the MgII doublet at z=0.942, with the 2797 AA component \\nsharing the absorption feature at 5430 AA with the MgII 2803 of the \\nsystem at z=0.937. This can be another line-locking example like that of \\nthe CIV system of GRB 021004 at z=2.3 (Fiore et al. 2005, ApJ, 624, 853; \\nStarling et al. 2005, MNRAS, 360, 305 ).\\n\\nFinally, we find another MgII doublet at ~4000 AA (z=0.370), not \\nconsistent with the Ca system at z=0.372. No emission lines are visible.\\n\\nIn summary our analysis of the FORS2 spectrum puts a lower limit on the \\nredshift of GRB 071003 to z=0.937.\\n\\nWe thank VLT staff for performing the observations, in particular Thomas \\nSzeifert and Alain Smette.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": -1,\n        \"max\": 12,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          2,\n          3,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"2_swift_bat_burst_xrt\",\n          \"3_mastersaao_masteroafa_masterkislovodsk_mastertunka\",\n          \"5_konuswind_grb_burst_ipn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representative_Docs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Top_n_words\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"swift - bat - burst - xrt - raj2000 - decj2000 - arcseconds - countssec - peak - uvot\",\n          \"mastersaao - masteroafa - masterkislovodsk - mastertunka - masternet - mastertavrida - masteriac - solar - akuznetsov - httpobservperepletru\",\n          \"konuswind - grb - burst - ipn - chi2 - triangulation - peak - ergcm2 - ulysses - hete\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Probability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4049438288916796,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2819,\n        \"samples\": [\n          0.6618836872903873,\n          0.9411064068109013,\n          0.8383749535284165\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representative_document\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "'''\n",
        "We will now perform topic modelling with BERTopic.\n",
        "We use the default all-MiniLM-L6-v2 and a minimum topic size of 100 which gave the best coherence score for this model.\n",
        "In addition, we will use a 4-bit quantized version of the new Mistral-7B-Instruct LLM for topic label generation.\n",
        "This open sorce model has been shown to have superior performance to Llama 2 13B on multiple benchmarks.\n",
        "It has been fine-tuned using publicly available conversation datasets.\n",
        "'''\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "from bertopic.representation import LlamaCPP\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from bertopic import BERTopic\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Set number of threads to 1 and set other os environment variables for reproducibility\n",
        "os.environ['OMP_NUM_THREADS'] = '1'\n",
        "os.environ['MKL_NUM_THREADS'] = '1'\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "seed_value = 42  # Set the random seed\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "# Build representation model with mistral and llama cpp\n",
        "# Use a custom prompt for label generation\n",
        "prompt = \"\"\"Q: I have a topic that contains the following representative circulars among hundreds of others:\n",
        "[DOCUMENTS]\n",
        "\n",
        "The topic is described by the following keywords: '[KEYWORDS]'.\n",
        "\n",
        "Based on the above information, can you give a short label of the topic?\n",
        "A: \"\"\"\n",
        "\n",
        "representation_model = LlamaCPP(model=llm,\n",
        "                                prompt=prompt,\n",
        "                                doc_length=768,\n",
        "                                tokenizer=tokenizer,\n",
        "                                pipeline_kwargs={\"max_tokens\": 128,\n",
        "                                                 \"stop\": \"Q:\",\n",
        "                                                 \"temperature\": 0.0})\n",
        "\n",
        "embeddings = np.load(\"minilm_l6_embeddings.npy\")\n",
        "\n",
        "# Fix random state in UMAP for reproducibility\n",
        "umap_model = UMAP(n_neighbors=30, # For balanced scientific topics (GW, GRB, Neutrino, Follow-up, etc.): 25–50\n",
        "                  n_components=5,\n",
        "                  min_dist=0.0,\n",
        "                  metric='cosine',\n",
        "                  low_memory=False,\n",
        "                  random_state=42) # fixed seed for reproducibility\n",
        "\n",
        "# Set number of cores to one to turn off multi-threading. This should help with reproducibility.\n",
        "# Set minimum cluster size to 800. This will iteratively merge smaller clusters to form bigger ones.\n",
        "# Set minimum samples to 10. This will make sure only clusters smaller than 10 are treated as outliers.\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=800,\n",
        "                        min_samples=10,\n",
        "                        metric='euclidean',\n",
        "                        cluster_selection_method='eom',\n",
        "                        prediction_data=True,\n",
        "                        core_dist_n_jobs=1)\n",
        "\n",
        "\n",
        "# Build Topic Model with BERTopic\n",
        "topic_model = BERTopic(verbose=True,\n",
        "                       umap_model=umap_model,\n",
        "                       hdbscan_model=hdbscan_model,\n",
        "                       vectorizer_model=vectorizer_model)\n",
        "\n",
        "topics, probs = topic_model.fit_transform(circular_bodies, embeddings)\n",
        "\n",
        "# -----------------------\n",
        "# Reduce to 10 Topics\n",
        "# -----------------------\n",
        "#topic_model.reduce_topics(circular_bodies, nr_topics=10)\n",
        "\n",
        "# Reuse the same embeddings when re-transforming\n",
        "#topics, probs = topic_model.transform(circular_bodies, embeddings=embeddings)\n",
        "\n",
        "end_time = time.time()\n",
        "print(end_time - start_time)\n",
        "\n",
        "# Display topics\n",
        "freq = topic_model.get_topic_info()\n",
        "freq.head(30)\n",
        "\n",
        "# Error Analysis\n",
        "document_info = topic_model.get_document_info(circular_bodies)\n",
        "document_info.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx53H5d5QMGE",
        "outputId": "af1c8fef-2fa6-480d-e58d-c32201429187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 40506 samples in 0.007s...\n",
            "[t-SNE] Computed neighbors for 40506 samples in 45.189s...\n",
            "[t-SNE] Computed conditional probabilities for sample 1000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 2000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 3000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 4000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 5000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 6000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 7000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 8000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 9000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 10000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 11000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 12000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 13000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 14000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 15000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 16000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 17000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 18000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 19000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 20000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 21000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 22000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 23000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 24000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 25000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 26000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 27000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 28000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 29000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 30000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 31000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 32000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 33000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 34000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 35000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 36000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 37000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 38000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 39000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 40000 / 40506\n",
            "[t-SNE] Computed conditional probabilities for sample 40506 / 40506\n",
            "[t-SNE] Mean sigma: 0.099260\n",
            "[t-SNE] Computed conditional probabilities in 1.098s\n",
            "[t-SNE] Iteration 50: error = 100.2614670, gradient norm = 0.0101262 (50 iterations in 29.632s)\n",
            "[t-SNE] Iteration 100: error = 93.1225510, gradient norm = 0.0038481 (50 iterations in 24.055s)\n",
            "[t-SNE] Iteration 150: error = 90.8637695, gradient norm = 0.0022994 (50 iterations in 24.044s)\n",
            "[t-SNE] Iteration 200: error = 89.6533051, gradient norm = 0.0017611 (50 iterations in 24.240s)\n",
            "[t-SNE] Iteration 250: error = 88.8921967, gradient norm = 0.0012554 (50 iterations in 36.239s)\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 88.892197\n",
            "[t-SNE] Iteration 300: error = 3.6661229, gradient norm = 0.0071017 (50 iterations in 20.788s)\n",
            "[t-SNE] Iteration 350: error = 2.9514685, gradient norm = 0.0068595 (50 iterations in 20.972s)\n",
            "[t-SNE] Iteration 400: error = 2.5698438, gradient norm = 0.0064243 (50 iterations in 18.538s)\n",
            "[t-SNE] Iteration 450: error = 2.3281813, gradient norm = 0.0060365 (50 iterations in 19.422s)\n",
            "[t-SNE] Iteration 500: error = 2.1627419, gradient norm = 0.0055801 (50 iterations in 18.265s)\n",
            "[t-SNE] Iteration 550: error = 2.0452611, gradient norm = 0.0050611 (50 iterations in 19.480s)\n",
            "[t-SNE] Iteration 600: error = 1.9576529, gradient norm = 0.0046342 (50 iterations in 18.479s)\n",
            "[t-SNE] Iteration 650: error = 1.8898172, gradient norm = 0.0042451 (50 iterations in 19.528s)\n",
            "[t-SNE] Iteration 700: error = 1.8357260, gradient norm = 0.0039289 (50 iterations in 18.636s)\n",
            "[t-SNE] Iteration 750: error = 1.7913812, gradient norm = 0.0036570 (50 iterations in 19.381s)\n",
            "[t-SNE] Iteration 800: error = 1.7541313, gradient norm = 0.0034469 (50 iterations in 18.783s)\n",
            "[t-SNE] Iteration 850: error = 1.7226989, gradient norm = 0.0032020 (50 iterations in 19.418s)\n",
            "[t-SNE] Iteration 900: error = 1.6956768, gradient norm = 0.0030032 (50 iterations in 19.077s)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Apply t-SNE to reduce the dimensionality of the embeddings and visualize the clusters.\n",
        "'''\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import itertools\n",
        "\n",
        "# reduced_embeddings = UMAP(n_components=2, random_state=0).fit_transform(embeddings)\n",
        "# reduced_embeddings = TSNE(n_components=2, n_jobs=1, random_state=0, verbose=2).fit_transform(embeddings)\n",
        "reduced_embeddings = TSNE(\n",
        "    n_components=2,\n",
        "    n_jobs=1,\n",
        "    random_state=42,\n",
        "    verbose=2,\n",
        "    learning_rate='auto',\n",
        "    init='pca'\n",
        ").fit_transform(embeddings)\n",
        "\n",
        "fig = go.Figure()\n",
        "tsne_df = pd.DataFrame()\n",
        "tsne_df[\"x\"], tsne_df[\"y\"] = reduced_embeddings[:, 0], reduced_embeddings[:, 1]\n",
        "tsne_df[\"topics\"] = [topic_model.topic_labels_[i] for i in topics]\n",
        "\n",
        "unique_topics = list(freq['Name'])[1:] # Exclude the outlier topic (-1) from unique topics\n",
        "# light24 = px.colors.qualitative.Light24\n",
        "# dark24 = px.colors.qualitative.Dark24\n",
        "# colors = light24[0:11] + [dark24[9]] + dark24[5:8] + dark24[15:17] + [dark24[13]] + [light24[22]] + [light24[17]]\n",
        "# color_cycle = itertools.cycle(colors)\n",
        "\n",
        "palette =  px.colors.qualitative.Viridis + px.colors.qualitative.T10 + px.colors.qualitative.Bold\n",
        "color_cycle = itertools.cycle(palette)\n",
        "\n",
        "\n",
        "for label in unique_topics:\n",
        "    sub_df = tsne_df.loc[tsne_df[\"topics\"] == label]\n",
        "    fig.add_trace(\n",
        "        go.Scattergl(\n",
        "            x=sub_df[\"x\"],\n",
        "            y=sub_df[\"y\"],\n",
        "            mode=\"markers\",\n",
        "            name=str(label[label.find('_')+1:]) + \" (\" + str(sub_df.shape[0]) + \")\",\n",
        "            marker=dict(\n",
        "                color=next(color_cycle),\n",
        "                size=6,\n",
        "                opacity=0.5,\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "fig.update_traces(\n",
        "  marker=dict(\n",
        "    size=6,\n",
        "    opacity=0.5,\n",
        "  )\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "  # title={\n",
        "  #   'text': \"<b>General Coordinates Network (GCN): Key Astrophysical Topics</b>\",\n",
        "  #   'x': 0.5,\n",
        "  #   'xanchor': 'center'\n",
        "  # },\n",
        "  width=1400,\n",
        "  height=800,\n",
        "  legend_title_text=\"Topics (Circular Counts)\",\n",
        "  legend=dict(\n",
        "    x=1.05,\n",
        "    y=1,\n",
        "    traceorder='normal',\n",
        "    bgcolor='rgba(0,0,0,0)',\n",
        "    bordercolor='rgba(0,0,0,0)',\n",
        "    font=dict(\n",
        "            size=18  # increase this value to make names larger\n",
        "        )\n",
        "  ),\n",
        "  xaxis=dict(\n",
        "    showticklabels=False\n",
        "  ),\n",
        "  yaxis=dict(\n",
        "    showticklabels=False\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCeD0mM38Zjc"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Generate topic summaries with Mistral 7B Instruct and update representations\n",
        "'''\n",
        "\n",
        "topic_model.update_topics(circular_bodies,\n",
        "                          representation_model=representation_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyjrfH39v5n-"
      },
      "outputs": [],
      "source": [
        "# Display topic summaries\n",
        "freq = topic_model.get_topic_info()\n",
        "freq.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9176kz3R3Dp"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Get table with just Topic Summaries and Frequencies\n",
        "'''\n",
        "sub_freq = freq[['Representation', 'Count']].copy()\n",
        "sub_freq['Topic Summary'] = freq['Representation'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)\n",
        "sub_freq['Circular Count'] = freq['Count']\n",
        "sub_freq.drop('Representation', axis=1, inplace=True)\n",
        "sub_freq.drop('Count', axis=1, inplace=True)\n",
        "\n",
        "sub_freq.drop(index=0, inplace=True) # Drop outlier row\n",
        "sub_freq\n",
        "\n",
        "sub_freq.to_csv('Unsupervised_Astrophysical_Topics.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEtHdsFg49mq"
      },
      "outputs": [],
      "source": [
        "latex_table = sub_freq.to_latex(index=False)\n",
        "latex_table\n",
        "\n",
        "'''\n",
        "Visualise topics in a 2-D space using UMAP\n",
        "'''\n",
        "topic_model.visualize_topics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HiAaiAmvfVG"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Perform hierarchical reduction on our topic model.\n",
        "Viualize these hierarchies to better understand the relations between our topics.\n",
        "'''\n",
        "\n",
        "hierarchical_topics = topic_model.hierarchical_topics(circular_bodies)\n",
        "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaUo9AHG-cga"
      },
      "outputs": [],
      "source": [
        "# Get topic IDs (exclude outlier -1)\n",
        "#valid_topics = [t for t in topic_model.get_topic_freq().Topic if t != -1]\n",
        "\n",
        "'''\n",
        "Visualize hierarchical topic clusters\n",
        "'''\n",
        "topic_model.visualize_hierarchical_documents(circular_bodies, hierarchical_topics, embeddings=embeddings, topics=list(range(10)))\n",
        "\n",
        "'''\n",
        "Display a Similarity Matrix for all Topics\n",
        "'''\n",
        "topic_model.visualize_heatmap(list(range(10)), width=650, height=650)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB6SJMkwDgvq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create word cloud over top 10 topics\n",
        "'''\n",
        "\n",
        "fig, axs = plt.subplots(10, 1, figsize=(10, 80)) # Create a figure with 10 subplots vertically arranged\n",
        "\n",
        "# Join all documents of a topic together and generate word cloud\n",
        "for topic_num, ax in enumerate(axs):\n",
        "    word_cloud = WordCloud(\n",
        "        collocations=True,\n",
        "        background_color='white',\n",
        "        max_words=100,\n",
        "        width=1000,\n",
        "        height=800,\n",
        "        stopwords=new_stop_words).generate(' '.join([text for i, text in enumerate(circular_bodies) if topics[i] == topic_num]))\n",
        "\n",
        "    ax.imshow(word_cloud, interpolation='bilinear')\n",
        "    ax.set_title(topic_model.topic_representations_[topic_num][0][0])\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMou7uHud53H"
      },
      "source": [
        "#Step 7: Trend Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGXU4WM-jZHl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "import plotly.express as px\n",
        "\n",
        "num_topics = len(freq) - 1  # Exclude outlier row\n",
        "\n",
        "# Plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_context(\"paper\", font_scale=1.5)\n",
        "\n",
        "# Modern color palette\n",
        "light24 = px.colors.qualitative.Light24\n",
        "dark24 = px.colors.qualitative.Dark24\n",
        "colors = light24[0:11] + dark24[5:10]\n",
        "color_cycle = itertools.cycle(colors)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "for k in range(num_topics):\n",
        "    topic_dates = []\n",
        "\n",
        "    for i, ts in enumerate(time_stamps):\n",
        "        if ts == 0:  # Skip invalid timestamps\n",
        "            continue\n",
        "        if topics[i] == k:\n",
        "            topic_dates.append(datetime.utcfromtimestamp(ts / 1000))\n",
        "\n",
        "    if len(topic_dates) == 0:\n",
        "        continue  # Skip empty topics\n",
        "\n",
        "    # Binning by 4 months\n",
        "    all_dates = [datetime.utcfromtimestamp(ts / 1000) for ts in time_stamps if ts != 0]\n",
        "    bins = pd.date_range(start=min(all_dates), end=max(all_dates), freq='4M')\n",
        "\n",
        "    # Use top 3 words as topic label\n",
        "    top_words = topic_model.get_topic(k)\n",
        "    if top_words is not None:\n",
        "        label_str = \", \".join([w for w, _ in top_words[:3]])\n",
        "    else:\n",
        "        label_str = f\"Topic {k}\"\n",
        "\n",
        "    sns.histplot(topic_dates,\n",
        "                 bins=mdates.date2num(bins),\n",
        "                 alpha=0.6,\n",
        "                 linewidth=0.2,\n",
        "                 color=next(color_cycle),\n",
        "                 ax=ax,\n",
        "                 label=label_str)\n",
        "\n",
        "# X-axis formatting\n",
        "ax.set_xlim(min(all_dates), max(all_dates))\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(2))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "plt.xlabel(\"Year\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Number of Circulars\", fontsize=14, fontweight=\"bold\")\n",
        "plt.title(\"Key GCN Topics Over Time\", fontsize=18, fontweight=\"bold\", y=1.02)\n",
        "\n",
        "# Grid and legend\n",
        "plt.grid(axis=\"both\", linestyle=\"--\", alpha=0.5)\n",
        "plt.legend(bbox_to_anchor=(0.5, -0.2), loc='upper center', fontsize=12, ncol=3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eTjdtEgSWK-"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Patch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "# Select key topics\n",
        "important_topics_list = [4, 11, 14, 22]\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_context(\"paper\", font_scale=1.5)\n",
        "\n",
        "# Modern, distinct colors\n",
        "custom_colors = ['#e8000b', '#023eff', '#ff7c00', '#1ac938']\n",
        "custom_palette = sns.color_palette(custom_colors)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "all_topic_dates = []\n",
        "all_dates = []\n",
        "\n",
        "# Collect topic dates\n",
        "for i, ts in enumerate(time_stamps):\n",
        "    if ts == 0:\n",
        "        continue\n",
        "    date = datetime.utcfromtimestamp(ts / 1000)\n",
        "    all_dates.append(date)\n",
        "    if topics[i] in important_topics_list:\n",
        "        topic = topic_model.topic_labels_[topics[i]]\n",
        "        all_topic_dates.append({'Date': date, 'Topic': topic})\n",
        "\n",
        "topic_dates_df = pd.DataFrame(all_topic_dates)\n",
        "\n",
        "# 6-month bins\n",
        "bins = pd.date_range(start=min(all_dates), end=max(all_dates), freq='6M')\n",
        "\n",
        "# Plot stacked histogram\n",
        "sns.histplot(topic_dates_df,\n",
        "             x='Date',\n",
        "             hue='Topic',\n",
        "             multiple='stack',\n",
        "             bins=mdates.date2num(bins),\n",
        "             alpha=0.75,\n",
        "             linewidth=0.2,\n",
        "             palette=custom_palette,\n",
        "             ax=ax)\n",
        "\n",
        "# X-axis formatting\n",
        "ax.set_xlim(min(all_dates), max(all_dates))\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(2))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "plt.xlabel(\"Year\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Number of Circulars\", fontsize=14, fontweight=\"bold\")\n",
        "plt.title(\"Selected Key GCN Topics Over Time\", fontsize=18, fontweight=\"bold\", y=1.02)\n",
        "\n",
        "# Grid & legend\n",
        "plt.grid(axis=\"both\", linestyle=\"--\", alpha=0.5)\n",
        "handles = [Patch(color=custom_colors[i],\n",
        "                 label=\", \".join([w for w, _ in topic_model.get_topic(important_topics_list[i])[:3]]))\n",
        "           for i in range(len(important_topics_list))]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(0.01, 0.99), loc='upper left', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}