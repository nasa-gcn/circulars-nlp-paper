{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nasa-gcn/circulars-nlp-paper/blob/main/topic-modeling/notebooks/custom_topic_clusters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwJAAp0A27Ay"
      },
      "source": [
        "#**Topic Modelling Pipeline for the NASA GCN Platform with Custom Topic Labels**\n",
        "The aim of this project is to leverage the power of BERTopic to build a transformer powered topic model for the NASA GCN circular database.\n",
        "\n",
        "It is recommended to run this notebook in Google Colab.\n",
        "\n",
        "To get results consistent with those reported in the paper, it is recommended to run each section in this notebook sequentially and only once. Re-running it without restarting the runtime may yield slightly different results in certain sections due to the inherently stochastic nature of some of the agorithms used. We also recommend using Google Colab's T4 GPU runtime, which is what we used in our work. This is not a requirement and any GPU runtime may suffice, however using a different runtime may once again produce minor deviations from the results in our paper, as variations in hardware configurations can affect the outcomes of some of the algorithms used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLBiaZreBVn9"
      },
      "source": [
        "# Step 0: User Input - Enter the list of topic labels (candidate_topics) into which you would like to classify the GCN Circular database into. For example: Gravitational Wave, High Energy, X-Rays, etc. Also enter a list of Circular IDs corresponding to each label (topic_1, topic_2, topic_3, etc.) for training. Add more topics as needed. We recommend about 30-40 circulars for each topic label to get ideal results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L762E3aFNVy"
      },
      "outputs": [],
      "source": [
        "# Enter list of topic labels. Ex: [\"Gravitational Wave\", \"High Energy\", \"X-Ray\"]\n",
        "candidate_topics = []\n",
        "\n",
        "# List of Circular ID's corresponding to each topic. Make sure order is consistent\n",
        "# with topic labels above. Add more as needed.\n",
        "topic_1 = [] # Ex: [38986, 38978]\n",
        "topic_2 = []\n",
        "topic_3 = []\n",
        "all_topics = [topic_1, topic_2, topic_3]\n",
        "\n",
        "for index, topic_list in enumerate(all_topics):\n",
        "  print(f'Number of Circulars in \"{candidate_topics[index]}\": {len(topic_list)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5edOPX82Nyc7"
      },
      "source": [
        "#STEP 1: Download And Unzip Necessary Files From Our Github Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKgxLYvxt90i"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/nasa-gcn/circulars-nlp-paper/raw/main/data/archive_2025.json.tar.gz -O /content/archive_2025.json.tar.gz\n",
        "!wget https://raw.githubusercontent.com/nasa-gcn/circulars-nlp-paper/main/data/custom_stopwords.txt -O /content/custom_stopwords.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQHTzlMLn3wl"
      },
      "source": [
        "#Step 2: Install Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-3bEceVaRCd"
      },
      "outputs": [],
      "source": [
        "%pip install bertopic==0.16.2 -qqq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qXSkpOy36e7"
      },
      "source": [
        "#Step 3: Extract GCN Circulars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4LBIsnqvN26"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Extract circular JSONs from tar file.\n",
        "'''\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "with tarfile.open('./archive_2025.json.tar.gz', 'r') as file:\n",
        "  file.extractall(path='./all_gcn_circulars')\n",
        "\n",
        "dir = os.listdir('./all_gcn_circulars/archive.json') # Store all file names as strings in dir\n",
        "\n",
        "# Add file path to beginning of file names in dir\n",
        "dir = ['./all_gcn_circulars/archive.json/' + filename for filename in sorted(dir)]\n",
        "\n",
        "print(f'Number of Circular JSONs: {len(dir)}\\n')\n",
        "print(f'First JSON path is: {dir[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRFBTZvpAOyX"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Extract circular bodies from JSON list.\n",
        "'''\n",
        "import json\n",
        "\n",
        "circulars = []\n",
        "circular_bodies = []\n",
        "time_stamps = []\n",
        "for file in dir:\n",
        "  with open(file, encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "    circulars.append(data)\n",
        "    circular_bodies.append(data[\"subject\"]+data[\"body\"])\n",
        "    time_stamps.append(data[\"createdOn\"])\n",
        "\n",
        "print(f'The first circular is:\\n {circulars[0]}\\n')\n",
        "print(f'The first circular body is:\\n {circular_bodies[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SZ7_xqgH8BG"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Remove all undefined characters.\n",
        "'''\n",
        "\n",
        "clean_texts = []\n",
        "for text in circular_bodies:\n",
        "  clean_text = text.replace('ï¿½', '')\n",
        "  clean_texts.append(clean_text)\n",
        "\n",
        "circular_bodies = clean_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqKXDs1FqgBb"
      },
      "source": [
        "#Step 4: Generate Custom Stopwords List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IJJcomqqPGP"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We will remove common English stopwords, punctuations, numbers, emails, and urls for preliminary statistical analysis and topic representations.\n",
        "We will also remove a hand-selected list of stopwords that do not add any value to our topics.\n",
        "As BERTopic uses a transformer based embedding model, it requires stopwords to build accurate embeddings.\n",
        "So removing stopwords before this step is unadvised.\n",
        "However, we can remove stopwords after embedding and clustering.\n",
        "We will use sklearn's WordVectorizer for this.\n",
        "'''\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "nltk.download('stopwords') # NLTK package for stopwords list\n",
        "\n",
        "new_stop_words = []\n",
        "new_stop_words = stopwords.words('english') # NLTK standard list of stopwords\n",
        "punctuation_list = list(string.punctuation) # Standard list of punctuations\n",
        "new_stop_words.extend(punctuation_list)\n",
        "\n",
        "# Get list of numbers and urls in circulars\n",
        "num_list = []\n",
        "url_list = []\n",
        "http_regex = re.compile(r\"http.*\")\n",
        "\n",
        "for text in circular_bodies:\n",
        "  word_list = text.split()\n",
        "\n",
        "  for word in word_list:\n",
        "    try:\n",
        "      float(word) # Check if word is numeric. Throws Value Error otherwise\n",
        "      num_list.append(word)\n",
        "    except ValueError:\n",
        "      pass\n",
        "\n",
        "    if re.match(http_regex, word): # Check if word begins with http\n",
        "      url_list.append(word)\n",
        "\n",
        "# Get list of emails\n",
        "email_list=[]\n",
        "for circular in circulars:\n",
        "  if \"email\" in circular:\n",
        "    email_list.append(circular[\"email\"])\n",
        "\n",
        "num_list = list(set(num_list)) # Remove duplicates\n",
        "new_stop_words.extend(num_list)\n",
        "\n",
        "url_list = list(set(url_list))\n",
        "new_stop_words.extend(url_list)\n",
        "\n",
        "email_list = list(set(email_list))\n",
        "new_stop_words.extend(email_list)\n",
        "\n",
        "with open('custom_stopwords.txt') as f:\n",
        "  for word in f:\n",
        "    new_stop_words.append(word.lower().strip())\n",
        "\n",
        "vectorizer_model = CountVectorizer(stop_words=new_stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nwZhk1A8OKt"
      },
      "source": [
        "#Step 5: Preliminary Statistical Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUAt4gbh8HPa"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Get word count distribution over all circulars.\n",
        "'''\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sns.set_theme()\n",
        "\n",
        "counts=[]\n",
        "for text in circular_bodies:\n",
        "  counts.append(len(text.split()))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(counts, range=(0,1000), bins=100, color=sns.color_palette(\"Set2\", 1))\n",
        "plt.xlabel(\"Word Count\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Word Counts of Circular Bodies\")\n",
        "plt.xticks(np.arange(0, 1001, 100))\n",
        "plt.show()\n",
        "\n",
        "counts_over_1000 = [count>1000 for count in counts]\n",
        "print(f'Number of circulars with > 1000 words: {sum(counts_over_1000)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McK57eQtbsZa"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create word cloud over all GCN circulars.\n",
        "Includes bigrams and trigrams of words.\n",
        "'''\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "word_cloud = WordCloud(\n",
        "    collocations = True,\n",
        "    background_color = 'white',\n",
        "    max_words=100,\n",
        "    width=800,\n",
        "    height=600,\n",
        "    stopwords=new_stop_words).generate(' '.join(circular_bodies))\n",
        "\n",
        "plt.imshow(word_cloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI6DdD6qMtd4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Print the list of words in the word cloud\n",
        "'''\n",
        "\n",
        "word_frequencies = word_cloud.words_\n",
        "words = list(word_frequencies.keys())\n",
        "for word in words:\n",
        "  print(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phnVmCY1HoBn"
      },
      "source": [
        "#Step 6: Embed GCN Circulars With The Default all-MiniLM-L6-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdyjnshP6nD_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Embed our circulars using the base all-MiniLM-L6-v2 model.\n",
        "'''\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Default model. Really fast, but only has context window of 256 tokens\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "minilm_l6_embeddings = model.encode(circular_bodies, show_progress_bar=True)\n",
        "np.save('minilm_l6_embeddings.npy', minilm_l6_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6KzPJs-9QOm"
      },
      "source": [
        "#Step 7: Embedding Model Evaluation For Circular Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdL4QULy9QOp"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We will now test out topc modelling pipeline with the default all-MiniLM-L6-v2 model.\n",
        "Our goal is to find the topic model that can correctly classify most of these circulars based on Zero-Shot Classification.\n",
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_observation_labels = [\"\"] * len(circulars)\n",
        "test_observation_labels = [\"\"] * len(circulars)\n",
        "\n",
        "# Get training and testing data for all topics\n",
        "for index, topic_list in enumerate(all_topics):\n",
        "  topic_train, topic_test = train_test_split(topic_list, test_size=0.2, random_state=0)\n",
        "\n",
        "  for i, circular in enumerate(circulars):\n",
        "        if circular[\"circularId\"] in topic_train:\n",
        "            train_observation_labels[i] = candidate_topics[index]\n",
        "        elif circular[\"circularId\"] in topic_test:\n",
        "            test_observation_labels[i] = candidate_topics[index]\n",
        "\n",
        "  print(f'Number of Circulars in \"{candidate_topics[index]}\": {len(topic_list)}')\n",
        "  print(f'Number of Circulars in \"{candidate_topics[index]}\" for training: {len(topic_train)}')\n",
        "  print(f'Number of Circulars in \"{candidate_topics[index]}\" for testing: {len(topic_test)}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgarLfxd9QOp"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We will perform Zero-Shot Topic Modelling to match circulars to pre-defined cadidate labels.\n",
        "We'll be using a cosine similarity with various thresholds to match topic labels to circulars.\n",
        "For the circulars that don't match any of the labels above our threshold we perform regular Topic Modelling.\n",
        "Finally, we calculate accuracy scores for each embedding model and cosine threshold based on our dataset.\n",
        "'''\n",
        "import pandas as pd\n",
        "from umap import UMAP\n",
        "\n",
        "embeddings_list = [\"Base Model\", \"Epoch 1\"]#, \"Epoch 2\", \"Epoch 3\"]\n",
        "accuracy_scores = pd.DataFrame(index=[\"Train\", \"Test\"], columns=embeddings_list)\n",
        "\n",
        "umap_model = UMAP(n_neighbors=15,\n",
        "                  n_components=5,\n",
        "                  min_dist=0.0,\n",
        "                  metric='cosine',\n",
        "                  low_memory=False,\n",
        "                  random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69x3A2NY9QOq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Compute accuracy for all-MiniLM-L6-v2 embeddings on training set\n",
        "'''\n",
        "from bertopic import BERTopic\n",
        "\n",
        "vectorizer_model = CountVectorizer()\n",
        "embeddings = np.load(\"minilm_l6_embeddings.npy\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "error_count=0\n",
        "\n",
        "# Compute accuracy scores based on number of matches between candidate labels and topic model labels\n",
        "topic_model = BERTopic(verbose=True,\n",
        "                       umap_model=umap_model,\n",
        "                       vectorizer_model=vectorizer_model,\n",
        "                       zeroshot_topic_list=candidate_topics,\n",
        "                       zeroshot_min_similarity=0.1, # Assign topic to each circular if it crosses threshold\n",
        "                       embedding_model=model)\n",
        "\n",
        "topics, probs = topic_model.fit_transform(circular_bodies, embeddings)\n",
        "\n",
        "topic_labels=[]\n",
        "for topic in topics:\n",
        "  topic_labels.append(topic_model.topic_labels_[topic])\n",
        "\n",
        "score = 0\n",
        "for i, label in enumerate(train_observation_labels):\n",
        "  if label != \"\":\n",
        "    if topic_labels[i] == label:\n",
        "      score += 1\n",
        "    else:\n",
        "      error_count += 1\n",
        "\n",
        "print(f\"Raw Score: {score}\")\n",
        "print(f\"Raw Error: {error_count}\")\n",
        "accuracy = (score / (score + error_count)) * 100\n",
        "accuracy_scores.at[\"Train\", \"Base Model\"] = accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruuAmQUa9QOq"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "Compute accuracy scores for base model on test set\n",
        "'''\n",
        "\n",
        "error_count=0\n",
        "\n",
        "topic_model = BERTopic(verbose=True,\n",
        "                      umap_model=umap_model,\n",
        "                      vectorizer_model=vectorizer_model,\n",
        "                      zeroshot_topic_list=candidate_topics,\n",
        "                      zeroshot_min_similarity=0.1,\n",
        "                      embedding_model=model)\n",
        "\n",
        "topics, probs = topic_model.fit_transform(circular_bodies, embeddings)\n",
        "\n",
        "topic_labels=[]\n",
        "for topic in topics:\n",
        "  topic_labels.append(topic_model.topic_labels_[topic])\n",
        "\n",
        "score = 0\n",
        "for i, label in enumerate(test_observation_labels):\n",
        "  if label != \"\":\n",
        "    if topic_labels[i] == label:\n",
        "      score += 1\n",
        "    else:\n",
        "      error_count += 1\n",
        "\n",
        "print(f\"Raw Score: {score}\")\n",
        "print(f\"Raw Error: {error_count}\")\n",
        "accuracy = (score / (score + error_count)) * 100\n",
        "accuracy_scores.at[\"Test\", \"Base Model\"] = accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCva6ZXO9QOq"
      },
      "outputs": [],
      "source": [
        "accuracy_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7nV7MV79vs_"
      },
      "source": [
        "# Step 8: Contrastive Fine-Tuning On Labelled Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7WsHYuv9vs_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We will now fine-tune our sentence embedder model using Contrastive Loss.\n",
        "The goal is to fine-tune our embeddings so that circulars belong to similar topics are embedded more closely,\n",
        "while circulars belonging to dissimilar topics are embedded far away in the vector space.\n",
        "Theoretically this should help improve our zero-shot topic modelling accuracy.\n",
        "'''\n",
        "\n",
        "# Prepare Dataset\n",
        "event_dataset = []\n",
        "for text, label in zip(circular_bodies, train_observation_labels):\n",
        "  example = {}\n",
        "  if label != \"\":\n",
        "    example[\"text\"] = text\n",
        "    example[\"label\"] = candidate_topics.index(label)\n",
        "    event_dataset.append(example)\n",
        "\n",
        "# Add label names to event dataset as well\n",
        "for label in candidate_topics:\n",
        "  example = {}\n",
        "  example[\"text\"] = label\n",
        "  example[\"label\"] = candidate_topics.index(label)\n",
        "  event_dataset.append(example)\n",
        "\n",
        "print(len(event_dataset))\n",
        "unique_values = {d[\"label\"] for d in event_dataset if \"label\" in d}\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i2ASofU9vtA"
      },
      "outputs": [],
      "source": [
        "# Prepare Similar Event Dataset\n",
        "event_pair_dataset = []\n",
        "for i in event_dataset:\n",
        "  for j in event_dataset:\n",
        "    # if i == j:\n",
        "    #   continue\n",
        "    example={}\n",
        "    example[\"texts\"] = [i[\"text\"], j[\"text\"]]\n",
        "    if i[\"label\"] == j[\"label\"]:\n",
        "      example[\"label\"] = 1\n",
        "    else:\n",
        "      example[\"label\"] = 0\n",
        "    event_pair_dataset.append(example)\n",
        "\n",
        "print(len(event_pair_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_Zjm5Kt9vtA"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Train for 1 epoch on the training set\n",
        "'''\n",
        "import torch\n",
        "import random\n",
        "from sentence_transformers.readers import InputExample\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import losses\n",
        "\n",
        "# Set seeds to help reproducibility\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "seed_value = 42\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "# Prepare Training Examples, Loss, and Model (all-MiniLM-L6-v2)\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "train_examples = [InputExample(texts=example[\"texts\"], label=example[\"label\"]) for example in event_pair_dataset]\n",
        "\n",
        "# Prepare DataLoader Object\n",
        "train_dataloader = DataLoader(train_examples,\n",
        "                              shuffle=True,\n",
        "                              batch_size=1,\n",
        "                              num_workers=0)\n",
        "train_size = len(train_dataloader)\n",
        "\n",
        "# Use Contrastive Training Loss\n",
        "train_loss = losses.ContrastiveLoss(model=model)\n",
        "\n",
        "# Tune the model\n",
        "model.old_fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "          epochs=1,\n",
        "          warmup_steps=100)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"fine_tuned_model_epoch_1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFrpjsXv9vtB"
      },
      "outputs": [],
      "source": [
        "# Get new all-MiniLM-L6-v2 embeddings\n",
        "fine_tuned_model_epoch_1 = SentenceTransformer(\"/content/fine_tuned_model_epoch_1\")\n",
        "fine_tuned_embeddings_epoch_1 = fine_tuned_model_epoch_1.encode(circular_bodies, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lNvcxufUAIa"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Compute training accuracy for fine-tuned all-MiniLM-L6-v2 embeddings\n",
        "'''\n",
        "\n",
        "error_count=0\n",
        "\n",
        "# Compute accuracy scores based on number of matches between candidate labels and topic model labels\n",
        "for i in range(1,2):\n",
        "  embeddings = eval(f\"fine_tuned_embeddings_epoch_{i}\")\n",
        "  model = eval(f\"fine_tuned_model_epoch_{i}\")\n",
        "  topic_model = BERTopic(verbose=True,\n",
        "                         umap_model=umap_model,\n",
        "                         vectorizer_model=vectorizer_model,\n",
        "                         zeroshot_topic_list=candidate_topics,\n",
        "                         zeroshot_min_similarity=0.1,\n",
        "                         embedding_model=model)\n",
        "\n",
        "  topics, probs = topic_model.fit_transform(circular_bodies, embeddings)\n",
        "\n",
        "  topic_labels=[]\n",
        "  for topic in topics:\n",
        "    topic_labels.append(topic_model.topic_labels_[topic])\n",
        "\n",
        "  score = 0\n",
        "  error_count = 0\n",
        "  for j, label in enumerate(train_observation_labels):\n",
        "    if label != \"\":\n",
        "      if topic_labels[j] == label:\n",
        "        score += 1\n",
        "      else:\n",
        "        error_count += 1\n",
        "\n",
        "  print(f\"Raw Score for Epoch {i}: {score}\")\n",
        "  print(f\"Raw Error for Epoch {i}: {error_count}\")\n",
        "  accuracy = (score / (score + error_count)) * 100\n",
        "  epoch = f\"Epoch {i}\"\n",
        "  accuracy_scores.at[\"Train\", epoch] = accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YX5l0_0Z9vtC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Compute test accuracy for fine-tuned all-MiniLM-L6-v2 embeddings\n",
        "'''\n",
        "\n",
        "error_count=0\n",
        "\n",
        "# Compute accuracy scores based on number of matches between candidate labels and topic model labels\n",
        "for i in range(1,2):\n",
        "  embeddings = eval(f\"fine_tuned_embeddings_epoch_{i}\")\n",
        "  model = eval(f\"fine_tuned_model_epoch_{i}\")\n",
        "  topic_model = BERTopic(verbose=True,\n",
        "                         umap_model=umap_model,\n",
        "                         vectorizer_model=vectorizer_model,\n",
        "                         zeroshot_topic_list=candidate_topics,\n",
        "                         zeroshot_min_similarity=0.1,\n",
        "                         embedding_model=model)\n",
        "\n",
        "  topics, probs = topic_model.fit_transform(circular_bodies, embeddings)\n",
        "\n",
        "  topic_labels=[]\n",
        "  for topic in topics:\n",
        "    topic_labels.append(topic_model.topic_labels_[topic])\n",
        "\n",
        "  score = 0\n",
        "  error_count = 0\n",
        "  for j, label in enumerate(test_observation_labels):\n",
        "    if label != \"\":\n",
        "      if topic_labels[j] == label:\n",
        "        score += 1\n",
        "      else:\n",
        "        error_count += 1\n",
        "\n",
        "  print(f\"Raw Score for Epoch {i}: {score}\")\n",
        "  print(f\"Raw Error for Epoch {i}: {error_count}\")\n",
        "  accuracy = (score / (score + error_count)) * 100\n",
        "  epoch = f\"Epoch {i}\"\n",
        "  accuracy_scores.at[\"Test\", epoch] = accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhapwGdZ9vtC"
      },
      "outputs": [],
      "source": [
        "accuracy_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5i6-FCX9vtC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create latex table for accuracy scores\n",
        "'''\n",
        "\n",
        "accuracy_latex_table = accuracy_scores.to_latex(float_format=\"%.2f\")\n",
        "accuracy_latex_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDkn8jghCbYL"
      },
      "source": [
        "#Step 9: Zero-Shot Topic Modelling For Circular Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmVNL2DbCbYM"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We'll now perform topic modelling again but with Zero-Shot enabled.\n",
        "We will use our fine-tuned all-MiniLM-L6-v2 model for this which was tuned for 1 epoch on the dataset.\n",
        "We attempt to fit our topics into pre-defined candidate labels using zero-shot topic modelling.\n",
        "'''\n",
        "\n",
        "umap_model = UMAP(n_neighbors=15,\n",
        "                  n_components=5,\n",
        "                  min_dist=0.0,\n",
        "                  metric='cosine',\n",
        "                  low_memory=False,\n",
        "                  random_state=0)\n",
        "\n",
        "# Build Topic Model with BERTopic\n",
        "topic_model = BERTopic(verbose=True,\n",
        "                       embedding_model=fine_tuned_model_epoch_1,\n",
        "                       umap_model=umap_model,\n",
        "                       min_topic_size=100,\n",
        "                       vectorizer_model=vectorizer_model,\n",
        "                       zeroshot_topic_list=candidate_topics,\n",
        "                       zeroshot_min_similarity=0.1)\n",
        "\n",
        "topics, probs = topic_model.fit_transform(circular_bodies, fine_tuned_embeddings_epoch_1)\n",
        "topic_labels = [value for key, value in topic_model.topic_labels_.items()]\n",
        "topic_model.set_topic_labels(topic_labels)\n",
        "\n",
        "freq = topic_model.get_topic_info()\n",
        "freq.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4hO7im5U_y3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create topic csv file\n",
        "'''\n",
        "from datetime import datetime\n",
        "\n",
        "circular_topic_df = pd.DataFrame()\n",
        "circular_topic_df[\"Circular ID\"] = [item[\"circularId\"] for item in circulars]\n",
        "circular_topic_df[\"Subject\"] = [item[\"subject\"] for item in circulars]\n",
        "circular_topic_df[\"Date\"] = [datetime.utcfromtimestamp(item[\"createdOn\"]/1000) for item in circulars]\n",
        "circular_topic_df[\"Label\"] = [topic_model.topic_labels_[i] for i in topics]\n",
        "\n",
        "# Sort by Circular ID\n",
        "circular_topic_df = circular_topic_df.sort_values(by=\"Circular ID\")\n",
        "\n",
        "circular_topic_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BlRta11uWME2"
      },
      "outputs": [],
      "source": [
        "circular_topic_df.to_csv('topics.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pde_l9YsCbYO"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Apply TSNE to reduce the dimensionality of the embeddings and visualize the clusters.\n",
        "'''\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "reduced_embeddings = TSNE(n_components=2, n_jobs=1, random_state=0, verbose=2).fit_transform(fine_tuned_embeddings_epoch_1)\n",
        "\n",
        "fig = go.Figure()\n",
        "tsne_df = pd.DataFrame()\n",
        "tsne_df[\"x\"], tsne_df[\"y\"] = reduced_embeddings[:, 0], reduced_embeddings[:, 1]\n",
        "tsne_df[\"topics\"] = [topic_model.topic_labels_[i] for i in topics]\n",
        "tsne_df[\"circular_id\"] = circular_topic_df[\"Circular ID\"]\n",
        "\n",
        "for label in list(topic_model.topic_labels_.values()):\n",
        "  sub_df = tsne_df.loc[tsne_df[\"topics\"] == label]\n",
        "  fig.add_trace(\n",
        "    go.Scattergl(\n",
        "      x=sub_df[\"x\"],\n",
        "      y=sub_df[\"y\"],\n",
        "      mode=\"markers\",\n",
        "      name=str(label[label.find('_')+1:]) + \" (\" + str(sub_df.shape[0]) + \")\",\n",
        "    )\n",
        "  )\n",
        "\n",
        "fig.update_traces(\n",
        "  marker=dict(\n",
        "    size=5,\n",
        "    opacity=0.5,\n",
        "  )\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "  title={\n",
        "    'text': \"<b>General Coordinates Network (GCN): Topic Clusters</b>\",\n",
        "    'x': 0.5,\n",
        "    'xanchor': 'center'\n",
        "  },\n",
        "  width=1200,\n",
        "  height=800,\n",
        "  legend_title_text=\"Topics (Circular Counts)\",\n",
        "  legend=dict(\n",
        "    x=1.05,\n",
        "    y=1,\n",
        "    traceorder='normal',\n",
        "    bgcolor='rgba(0,0,0,0)',\n",
        "    bordercolor='rgba(0,0,0,0)',\n",
        "    font=dict(size=16)\n",
        "  ),\n",
        "  xaxis=dict(\n",
        "    showticklabels=False\n",
        "  ),\n",
        "  yaxis=dict(\n",
        "    showticklabels=False\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDvmPLplCbYO"
      },
      "outputs": [],
      "source": [
        "# Display a Similarity Matrix for all Topics\n",
        "topic_model.visualize_heatmap(width=850, height=650, custom_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkxBLtv9CbYO"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create word cloud over our candidate topics\n",
        "'''\n",
        "\n",
        "fig, axs = plt.subplots(len(candidate_topics), 1, figsize=(10, 60))\n",
        "\n",
        "# Join all documents of a candidate topic together and generate word cloud\n",
        "for topic_num, ax in enumerate(axs):\n",
        "  word_cloud = WordCloud(\n",
        "        collocations=True,\n",
        "        background_color='white',\n",
        "        max_words=100,\n",
        "        width=1000,\n",
        "        height=800).generate(' '.join([text for i, text in enumerate(circular_bodies) if topic_model.topic_labels_[topics[i]] == candidate_topics[topic_num]]))\n",
        "\n",
        "  ax.imshow(word_cloud, interpolation='bilinear')\n",
        "  ax.set_title(candidate_topics[topic_num], fontsize=18, fontweight=\"bold\", y=1.05)\n",
        "  ax.axis(\"off\")\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncXPS2PKCbYP"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We will now perform Trend Analysis over our Topic Clusters.\n",
        "'''\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.patches import Patch\n",
        "from datetime import datetime\n",
        "\n",
        "num_topics = len(freq)\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_style(\"ticks\")\n",
        "sns.set_context(\"paper\", font_scale=1.5)\n",
        "plt.figure(figsize=(18, 6))\n",
        "custom_colors = sns.color_palette(n_colors=len(candidate_topics))\n",
        "custom_palette =  sns.color_palette(custom_colors)\n",
        "\n",
        "all_topic_dates = []\n",
        "all_dates = [] # List to store all dates\n",
        "\n",
        "# Iterate over all timestamps and check their respective document's topic\n",
        "for i, time_stamp in enumerate(time_stamps):\n",
        "  if time_stamp == 0: # Discard invalid dates\n",
        "      continue\n",
        "  date = datetime.utcfromtimestamp(time_stamp/1000)\n",
        "  topic = topic_model.topic_labels_[topics[i]]\n",
        "  all_topic_dates.append({'Date': date, 'Topic': topic})\n",
        "  all_dates.append(date)\n",
        "\n",
        "topic_dates_df = pd.DataFrame(all_topic_dates)\n",
        "my_bins = pd.date_range(start=min(all_dates), end=max(all_dates), freq='6M')\n",
        "sns.histplot(topic_dates_df,\n",
        "             x='Date',\n",
        "             hue='Topic',\n",
        "             multiple=\"stack\",\n",
        "             bins=mdates.date2num(my_bins),\n",
        "             alpha=0.75,\n",
        "             linewidth=0.2,\n",
        "             palette=custom_palette)\n",
        "\n",
        "# Calculate the number of 6-month intervals between start and end dates\n",
        "start_date = min(all_dates)\n",
        "end_date = max(all_dates)\n",
        "num_intervals = (end_date.year - start_date.year) * 2 + (end_date.month - start_date.month) // 6\n",
        "\n",
        "# Calculate the adjusted end date based on the number of intervals\n",
        "adjusted_end_date = start_date + pd.DateOffset(months=num_intervals * 6)\n",
        "\n",
        "plt.xlim(start_date, adjusted_end_date)\n",
        "plt.gca().xaxis.set_major_locator(mdates.YearLocator(2))\n",
        "plt.xlabel(\"Year\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Number of Circulars\", fontsize=14, fontweight=\"bold\")\n",
        "plt.title(\"Stacked Histogram of Topics over Time\", fontsize=18, fontweight=\"bold\", y=1.02)\n",
        "plt.grid(axis=\"both\", linestyle=\"-\", alpha=0.5)\n",
        "handles = [Patch(color=custom_colors[i], label=topic_model.topic_labels_[i]) for i in range(len(custom_colors))]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(0.01, 0.99), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BLBiaZreBVn9",
        "5edOPX82Nyc7",
        "dQHTzlMLn3wl",
        "4qXSkpOy36e7",
        "QqKXDs1FqgBb",
        "8nwZhk1A8OKt",
        "phnVmCY1HoBn",
        "I6KzPJs-9QOm"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
